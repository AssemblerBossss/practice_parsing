import json
import torch
import pandas as pd
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm
from itertools import combinations

from storage import DataStorage

# === –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ ===
EMBEDDINGS_CACHE = {}
VISITED_POSTS_CACHE = {}

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ SentenceTransformers —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º ===
print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ SentenceTransformers...")
# –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å paraphrase-multilingual-MiniLM-L12-v2
model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
model = model.to(DEVICE)
print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ç–µ–∫—Å—Ç–∞ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
def get_embedding(text, post_id=None):
    """
    –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è.
    –ï—Å–ª–∏ –ø–æ—Å—Ç —É–∂–µ –±—ã–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –µ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥ –∏–∑ –∫—ç—à–∞.
    """
    if post_id and post_id in EMBEDDINGS_CACHE:
        return EMBEDDINGS_CACHE[post_id]

    emb = model.encode(text, device=str(DEVICE))

    if post_id:
        EMBEDDINGS_CACHE[post_id] = emb

    return emb

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏ –º–µ–∂–¥—É –¥–≤—É–º—è —Ç–µ–∫—Å—Ç–∞–º–∏
def calculate_similarity(text1, text2):
    emb1 = get_embedding(text1)
    emb2 = get_embedding(text2)
    return cosine_similarity([emb1], [emb2])[0][0]

# –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ Telegram –ø–æ—Å—Ç–∞—Ö
def remove_telegram_duplicates(telegram_posts, threshold=0.97):
    filtered_posts = []
    seen = set()

    print("üßπ –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑ Telegram-–ø–æ—Å—Ç–æ–≤...")

    for i, post_i in enumerate(tqdm(telegram_posts)):
        post_id_i = post_i['id']

        # –ö—ç—à–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å—Ç–∞
        emb_i = get_embedding(post_i['text'], post_id_i)

        if i in seen:
            continue
        best_j = i
        for j in range(i + 1, len(telegram_posts)):
            post_j = telegram_posts[j]
            post_id_j = post_j['id']

            # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–∑ –∫—ç—à–∞ –∏–ª–∏ –≤—ã—á–∏—Å–ª—è–µ–º –∑–∞–Ω–æ–≤–æ
            emb_j = get_embedding(post_j['text'], post_id_j)
            sim = cosine_similarity([emb_i], [emb_j])[0][0]

            if sim > threshold:
                views_j = post_j.get('views') or 0
                views_best = telegram_posts[best_j].get('views') or 0
                best_j = j if views_j > views_best else best_j
                seen.add(j)

        filtered_posts.append(telegram_posts[best_j])
        seen.add(best_j)

    return filtered_posts

# –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Å—Ç–æ–≤ –º–µ–∂–¥—É Habr –∏ Telegram
def match_posts(habr_posts, telegram_posts, threshold=0.9):
    matches = []
    unmatched_habr = []
    used_telegram_ids = set()

    print("üîç –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Å—Ç–æ–≤...")

    for habr in tqdm(habr_posts):
        best_match = None
        best_score = 0

        habr_content = habr['content']
        for tele in telegram_posts:
            if tele['id'] in used_telegram_ids:
                continue

            score = calculate_similarity(habr_content, tele['text'])
            if score > best_score:
                best_score = score
                best_match = tele

        if best_score >= threshold:
            matches.append({
                "habr_title": habr['title'],
                "habr_date": habr['date'],
                "telegram_id": best_match['id'],
                "telegram_date": best_match['date'],
                "similarity": best_score,
                "habr_text": habr['content'],
                "telegram_text": best_match['text']
            })
            used_telegram_ids.add(best_match['id'])
        else:
            unmatched_habr.append(habr)

    return matches, unmatched_habr

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ Excel
def save_to_excel(matched, unmatched, matched_path='matched_posts.xlsx', unmatched_path='unmatched_habr.xlsx'):
    matched_df = pd.DataFrame(matched)
    unmatched_df = pd.DataFrame(unmatched)

    matched_df.to_excel(matched_path, index=False)
    unmatched_df.to_excel(unmatched_path, index=False)
    print(f"‚úÖ –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –ø–∞—Ä—ã –∑–∞–ø–∏—Å–∞–Ω—ã –≤ {matched_path}")
    print(f"üìÑ –ù–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Ö–∞–±—Ä-–ø–æ—Å—Ç—ã –∑–∞–ø–∏—Å–∞–Ω—ã –≤ {unmatched_path}")

# === –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
habr_posts = DataStorage.read_json('habr')
telegram_posts = DataStorage.read_json('telegram')

# === –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ ===
telegram_posts = remove_telegram_duplicates(telegram_posts)

# === –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Å—Ç–æ–≤ ===
matched, unmatched = match_posts(habr_posts, telegram_posts)

# === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ===
save_to_excel(matched, unmatched)
