import re
import torch
from logging import DEBUG
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm

from storage import DataStorage
from loggers import setup_logger
from models import HabrPostModel, TelegramPostModel

logger = setup_logger(__name__, log_file="content_comporator_bert.log", log_level=DEBUG)

EMBEDDINGS_CACHE:    dict[str, torch.tensor] = {}
VISITED_POSTS_CACHE: dict[str, bool] = {}


class PostMatcher:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–æ—Å—Ç–æ–≤ –º–µ–∂–¥—É Habr, Telegram –∏ Pikabu –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å Sentence Transformers –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Ç–µ–∫—Å—Ç–æ–≤
    –∏ –≤—ã—á–∏—Å–ª—è–µ—Ç –∏—Ö –∫–æ—Å–∏–Ω—É—Å–Ω—É—é —Å—Ö–æ–∂–µ—Å—Ç—å –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –ø–∞—Ä–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤.

    Attributes:
        threshold_duplicate (float): –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        threshold_match (float): –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–æ—Å—Ç–æ–≤
        device (torch.device): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (CPU/GPU)
        model (SentenceTransformer): –ú–æ–¥–µ–ª—å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ç–µ–∫—Å—Ç–∞
    """

    def __init__(self, threshold_duplicate_: float = 0.9, threshold_match_: float = 0.65):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç PostMatcher —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.

        Args:
            threshold_duplicate_: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.9)
            threshold_match_: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.65)
        """
        self.threshold_duplicate = threshold_duplicate_
        self.threshold_match = threshold_match_

        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        logger.info("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ SentenceTransformers...")
        self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        self.model = self.model.to(self.device)
        logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

    @staticmethod
    def normalize_text(text: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç: –∑–∞–º–µ–Ω—è–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –æ–¥–∏–Ω, –æ–±—Ä–µ–∑–∞–µ—Ç
         –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É."""
        text = re.sub(r'\s+', ' ', text)
        return text.strip().lower()

    def get_embeddings_for_posts(self, posts: list, key: str = 'text') -> list[torch.Tensor]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è —Å–ø–∏—Å–∫–∞ –ø–æ—Å—Ç–æ–≤.

        :param posts: –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ HabrPostModel –∏–ª–∏ TelegramPostModel
        :param key: –ö–ª—é—á, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ –ø–æ–ª–µ —Å —Ç–µ–∫—Å—Ç–æ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'content' –¥–ª—è Habr –∏ 'text' –¥–ª—è Telegram)
        :return: –°–ø–∏—Å–æ–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        """

        texts = [self.normalize_text(post.content) for post in posts]
        with torch.no_grad():
            embeddings = self.model.encode(
                texts,
                batch_size=16,
                show_progress_bar=True,
                device=str(self.device)
            )
            return [torch.from_numpy(embedding) for embedding in embeddings]

    def remove_telegram_duplicates(self, telegram_posts: list[TelegramPostModel], threshold=0.90) -> list[TelegramPostModel]:
        """
        –£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ—Å—Ç–æ–≤ Telegram –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏.

        :param telegram_posts: –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        :param threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        :return: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
        """
        logger.info("üßπ –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑ Telegram-–ø–æ—Å—Ç–æ–≤...")
        filtered_posts = []
        seen = set()

        embeddings = self.get_embeddings_for_posts(telegram_posts, key='text')

        for i, _ in enumerate(tqdm(telegram_posts)):
            if i in seen:
                continue
            best_j = i
            for j in range(i + 1, len(telegram_posts)):
                if j in seen:
                    continue
                sim = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]
                if sim > threshold:
                    views_j = telegram_posts[j].views or 0
                    views_best = telegram_posts[best_j].views or 0
                    best_j = j if views_j > views_best else best_j
                    seen.add(j)

            filtered_posts.append(telegram_posts[best_j])
            seen.add(best_j)

        return filtered_posts

    def match_posts(self, habr_posts: list[HabrPostModel], telegram_posts: list[TelegramPostModel]):
        """
        –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ—Å—Ç—ã –º–µ–∂–¥—É –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º–∏ Habr –∏ Telegram –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏.

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ—Å—Ç–æ–≤ –∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –ø–∞—Ä –ø–æ—Å—Ç–æ–≤.

        :param habr_posts: –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ HabrPostModel
        :param telegram_posts: –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ TelegramPostModel
        :return: –ö–æ—Ä—Ç–µ–∂ –∏–∑:
            - –°–ø–∏—Å–∫–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞—Ä (—Å–æ –≤—Å–µ–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –æ –ø–æ—Å—Ç–∞—Ö)
            - –°–ø–∏—Å–∫–∞ –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ —Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã Habr
            - –°–ø–∏—Å–∫–∞ –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ —Å –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã Telegram
        """
        logger.info("üì• –ü–æ–ª—É—á–µ–Ω–æ %s –ø–æ—Å—Ç–æ–≤ –∏–∑ Habr –∏ %s –∏–∑ Telegram.",
                    len(habr_posts), len(telegram_posts)
                    )
        logger.info("üîç –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Å—Ç–æ–≤ Habr –∏ Telegram...")

        matches = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∞—Ä
        unmatched_habr = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ Habr
        unmatched_telegram = []  # –°–ø–∏—Å–æ–∫ –¥–ª—è –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ Telegram
        used_telegram_ids = set()  # –ú–Ω–æ–∂–µ—Å—Ç–≤–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤ –ø–æ—Å—Ç–æ–≤ Telegram

        habr_embeddings = self.get_embeddings_for_posts(habr_posts, key='content')
        telegram_embeddings = self.get_embeddings_for_posts(telegram_posts, key='text')

        for i, habr in enumerate(tqdm(habr_posts)):
            best_match_idx = None
            best_score = 0

            for j, tele in enumerate(telegram_posts):
                if tele.id in used_telegram_ids:
                    continue

                score = cosine_similarity([habr_embeddings[i]], [telegram_embeddings[j]])[0][0]
                if score > best_score:
                    best_score = score
                    best_match_idx = j

            if best_score >= self.threshold_match:
                best_match = telegram_posts[best_match_idx]
                matches.append({
                    "habr_title": habr.title,
                    "habr_date": habr.date,
                    "telegram_id": best_match.post_url,
                    "telegram_date": best_match.date,
                    "similarity": best_score,
                    "habr_content": habr.content,
                    "telegram_content": best_match.content
                })
                used_telegram_ids.add(best_match.id)

                logger.debug("# –ù–∞–π–¥–µ–Ω–∞ –ø–∞—Ä–∞ #:")
                logger.debug("Habr:  %s:  %s ", habr.title, habr.date)
                logger.debug("Telegram (ID: %s),: %s", best_match.id, best_match.date)
                logger.debug("–û—Ü–µ–Ω–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏: %s", {best_score: .2})
                logger.debug("-" * 100)
            else:
                unmatched_habr.append(habr)
        logger.info("‚úÖ –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ %s –ø–∞—Ä.", len(matches))
        logger.info("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ä—ã –¥–ª—è %s habr-–ø–æ—Å—Ç–æ–≤.", len(unmatched_habr))

        logger.info("üîç –ü–æ–∏—Å–∫ –ø–æ—Å—Ç–æ–≤ Telegram, –∫–æ—Ç–æ—Ä—ã–º –Ω–µ –Ω–∞—à–ª–æ—Å—å –ø–∞—Ä—ã...")
        for post in tqdm(telegram_posts):
            if post.id not in used_telegram_ids:
                unmatched_telegram.append(post)
        logger.info("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–∞—Ä—ã –¥–ª—è %s telegram-–ø–æ—Å—Ç–æ–≤.", len(unmatched_telegram))

        return matches, unmatched_habr, unmatched_telegram


def start(telegram_posts: list[TelegramPostModel], habr_posts: list[HabrPostModel]):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–æ—Å—Ç–æ–≤ Habr –∏ Telegram.

    –ß–∏—Ç–∞–µ—Ç –ø–æ—Å—Ç—ã –∏–∑ JSON-—Ñ–∞–π–ª–æ–≤, —É–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ Telegram-–ø–æ—Å—Ç–∞—Ö,
    —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ—Å—Ç—ã –º–µ–∂–¥—É –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º–∏ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Excel.
    """

    matcher = PostMatcher()
    telegram_posts = matcher.remove_telegram_duplicates(telegram_posts)
    matched, unmatched_habr, unmatched_telegram  = matcher.match_posts(habr_posts, telegram_posts)
    #DataStorage.save_to_excel(matched, unmatched_habr, unmatched_telegram)
