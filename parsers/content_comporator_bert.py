import re
import torch
from logging import DEBUG
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm

from storage import DataStorage
from loggers import setup_logger
from models import HabrPostModel, TelegramPostModel, PikabuPostModel

logger = setup_logger(__name__, log_file="content_comporator_bert.log", log_level=DEBUG)

EMBEDDINGS_CACHE: dict[str, torch.tensor] = {}
VISITED_POSTS_CACHE: dict[str, bool] = {}


class PostMatcher:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–æ—Å—Ç–æ–≤ –º–µ–∂–¥—É Habr, Telegram –∏ Pikabu –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞.

    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª—å Sentence Transformers –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Ç–µ–∫—Å—Ç–æ–≤
    –∏ –≤—ã—á–∏—Å–ª—è–µ—Ç –∏—Ö –∫–æ—Å–∏–Ω—É—Å–Ω—É—é —Å—Ö–æ–∂–µ—Å—Ç—å –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –ø–∞—Ä–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤.

    Attributes:
        threshold_duplicate (float): –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        threshold_match (float): –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–æ—Å—Ç–æ–≤
        device (torch.device): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π (CPU/GPU)
        model (SentenceTransformer): –ú–æ–¥–µ–ª—å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Ç–µ–∫—Å—Ç–∞
    """

    def __init__(self, threshold_duplicate_: float = 0.9, threshold_match_: float = 0.65):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç PostMatcher —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.

        :param threshold_duplicate_: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.9)
        :param threshold_match_: –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.65)
        """
        self.threshold_duplicate = threshold_duplicate_
        self.threshold_match = threshold_match_

        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        logger.info("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ SentenceTransformers...")
        self.model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        self.model = self.model.to(self.device)
        logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")

    @staticmethod
    def normalize_text(text: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç: –∑–∞–º–µ–Ω—è–µ—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –æ–¥–∏–Ω, –æ–±—Ä–µ–∑–∞–µ—Ç
         –∏ –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É."""
        text = re.sub(r'\s+', ' ', text)
        return text.strip().lower()

    def get_embeddings_for_posts(self, posts: list) -> list[torch.Tensor]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –¥–ª—è —Å–ø–∏—Å–∫–∞ –ø–æ—Å—Ç–æ–≤.

        :param posts: –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ HabrPostModel –∏–ª–∏ TelegramPostModel
        :return: –°–ø–∏—Å–æ–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        """

        texts = [self.normalize_text(post.content) for post in posts]
        with torch.no_grad():
            embeddings = self.model.encode(
                texts,
                batch_size=16,
                show_progress_bar=True,
                device=str(self.device)
            )
            return [torch.from_numpy(embedding) for embedding in embeddings]

    def remove_duplicates(self, posts: list) -> list:
        """
        –£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ—Å—Ç–æ–≤ Telegram –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏.

        :param posts: –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        :return: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
        """
        logger.info("üßπ –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏–∑ %s –ø–æ—Å—Ç–æ–≤...", len(posts))
        filtered_posts = []
        seen = set()

        embeddings = self.get_embeddings_for_posts(posts)

        seen = set()

        for i, post in enumerate(tqdm(posts)):
            if i in seen:
                continue

            best_idx = i  # Initialize with current index
            for j in range(i + 1, len(posts)):
                if j in seen:
                    continue

                sim = cosine_similarity([embeddings[i]], [embeddings[j]])[0][0]
                if sim > self.threshold_duplicate:
                    # –î–ª—è Telegram –≤—ã–±–∏—Ä–∞–µ–º –ø–æ—Å—Ç —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –ø—Ä–æ—Å–º–æ—Ç—Ä–æ–≤
                    if hasattr(posts[j], 'views') and hasattr(posts[best_idx], 'views'):
                        if (posts[j].views or 0) > (posts[best_idx].views or 0):
                            best_idx = j
                    seen.add(j)

            # Ensure we only add valid posts
            if best_idx < len(posts):  # Additional safety check
                filtered_posts.append(posts[best_idx])
                seen.add(best_idx)

        logger.info(f"‚úÖ –û—Å—Ç–∞–≤–ª–µ–Ω–æ {len(filtered_posts)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤.")
        return filtered_posts

    def match_all_posts(self,
                        habr_posts: list[HabrPostModel],
                        telegram_posts: list[TelegramPostModel],
                        pikabu_posts: list[PikabuPostModel]) \
            -> tuple:
        """
        –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ—Å—Ç—ã –º–µ–∂–¥—É –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞–º–∏ Habr –∏ Telegram –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏.

        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø–æ—Å—Ç–æ–≤ –∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–ª—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –ø–∞—Ä –ø–æ—Å—Ç–æ–≤.

        :param habr_posts:     –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ HabrPostModel
        :param telegram_posts: –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ TelegramPostModel
        :param pikabu_posts:   –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ PikabuPostModel

        :return:
            –ö–æ—Ä—Ç–µ–∂ –∏–∑:
            - –°–ø–∏—Å–æ–∫ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ Habr —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è–º–∏
            - –°–ø–∏—Å–æ–∫ –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ Habr
            - –°–ø–∏—Å–æ–∫ –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ Telegram
            - –°–ø–∏—Å–æ–∫ –Ω–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤ Pikabu
        """

        logger.info("üì• –ü–æ–ª—É—á–µ–Ω–æ %s –ø–æ—Å—Ç–æ–≤ Habr, %s Telegram, %s Pikabu",
                    len(habr_posts), len(telegram_posts), len(pikabu_posts))

        telegram_posts = self.remove_duplicates(telegram_posts)
        pikabu_posts = self.remove_duplicates(pikabu_posts)

        habr_embeddings = self.get_embeddings_for_posts(habr_posts)
        telegram_embeddings = self.get_embeddings_for_posts(telegram_posts)
        pikabu_embeddings = self.get_embeddings_for_posts(pikabu_posts)

        matched_habr = []
        unmatched_habr = []
        used_telegram = set()
        used_pikabu = set()

        for i, habr_post in enumerate(tqdm(habr_posts, desc="üîç –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Å—Ç–æ–≤ Habr, Telegram –∏ Pikabu...")):
            habr_emb = habr_embeddings[i]

            # –ü–æ–∏—Å–∫ –ª—É—á—à–µ–≥–æ Telegram –ø–æ—Å—Ç–∞
            best_telegram = None
            best_telegram_score = 0
            for j, tele_post in enumerate(telegram_posts):
                if j in used_telegram:
                    continue
                score = cosine_similarity([habr_emb], [telegram_embeddings[j]])[0][0]
                if score > best_telegram_score and score >= self.threshold_match:
                    best_telegram_score = score
                    best_telegram = tele_post
                    best_telegram_index = j

            # –ü–æ–∏—Å–∫ –ª—É—á—à–µ–≥–æ Pikabu –ø–æ—Å—Ç–∞
            best_pikabu = None
            best_pikabu_score = 0
            for k, pika_post in enumerate(pikabu_posts):
                if k in used_pikabu:
                    continue
                score = cosine_similarity([habr_emb], [pikabu_embeddings[k]])[0][0]
                if score > best_pikabu_score and score >= self.threshold_match:
                    best_pikabu_score = score
                    best_pikabu = pika_post
                    best_pikabu_index = k

            if best_telegram or best_pikabu:
                matched_habr.append({
                    "habr_title": habr_post.title,
                    "habr_date": habr_post.date,
                    "habr_content": habr_post.content,
                    "telegram_url": best_telegram.post_url if best_telegram else None,
                    "telegram_date": best_telegram.date if best_telegram else None,
                    "telegram_content": best_telegram.content if best_telegram else None,
                    "telegram_similarity": best_telegram_score if best_telegram else 0,
                    "pikabu_title": best_pikabu.title if best_pikabu else None,
                    "pikabu_date": best_pikabu.date if best_pikabu else None,
                    "pikabu_url": best_pikabu.post_url if best_pikabu else None,
                    "pikabu_content": best_pikabu.content if best_pikabu else None,
                    "pikabu_similarity": best_pikabu_score if best_pikabu else 0
                })
                if best_telegram:
                    used_telegram.add(best_telegram_index)
                if best_pikabu:
                    used_pikabu.add(best_pikabu_index)
            else:
                unmatched_habr.append(habr_post)

        unmatched_telegram = [post for i, post in enumerate(telegram_posts) if i not in used_telegram]
        unmatched_pikabu = [post for i, post in enumerate(pikabu_posts) if i not in used_pikabu]

        logger.info("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è:")
        logger.info(f"‚úÖ –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –ø–æ—Å—Ç–æ–≤ Habr: {len(matched_habr)}")
        logger.info(f"‚ùå –ù–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –ø–æ—Å—Ç–æ–≤ Habr: {len(unmatched_habr)}")
        logger.info(f"‚ùå –ù–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –ø–æ—Å—Ç–æ–≤ Telegram: {len(unmatched_telegram)}")
        logger.info(f"‚ùå –ù–µ—Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ –ø–æ—Å—Ç–æ–≤ Pikabu: {len(unmatched_pikabu)}")

        return matched_habr, unmatched_habr, unmatched_telegram, unmatched_pikabu

def start(habr_posts: list[HabrPostModel],
          telegram_posts: list[TelegramPostModel],
          pikabu_posts: list[PikabuPostModel]):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø–æ—Å—Ç–æ–≤.

    :param habr_posts:     –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ —Å Habr
    :param telegram_posts: –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ —Å Telegram
    :param pikabu_posts:   –°–ø–∏—Å–æ–∫ –ø–æ—Å—Ç–æ–≤ —Å Pikabu
    """
    matcher = PostMatcher()

    # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å—Ç—ã
    matched, unmatched_habr, unmatched_telegram, unmatched_pikabu = matcher.match_all_posts(
        habr_posts, telegram_posts, pikabu_posts)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    DataStorage.save_to_excel(matched, unmatched_habr, unmatched_telegram, unmatched_pikabu)
